kde_list[[name]] <- kde
} else {
cat("Deleting KDE result for", name, "due to fewer than 5 relocations.\n")
# Delete this subset from the list
kde_list[[name]] <- NULL
}
}
# Get unique names from df_move$Code
unique_names <- unique(df_move$Code)
# Initialize an empty list to store KDE results
kde_list <- list()
# Loop through each unique "code name"
for (name in unique(df_move$Code)) {
# Subset the data for the current code name
subset_data <- df_move[df_move$Code == name, ]
# Check the number of relocations
num_relocations <- nrow(subset_data)
# Proceed if there are at least 5 relocations
if (num_relocations >= 5) {
# Convert subset_data to SpatialPointsDataFrame
subset_sp <- st_as_sf(subset_data, coords = c("x", "y"))
# Calculate kernel UD
kde <- kernelUD(subset_sp, h = parh)
kde_list[[name]] <- kde
} else {
cat("Deleting KDE result for", name, "due to fewer than 5 relocations.\n")
# Delete this subset from the list
kde_list[[name]] <- NULL
}
}
# Initialize an empty list to store KDE results
kde_list <- list()
# Loop through each unique "code name"
for (name in unique(df_move$Code)) {
# Subset the data for the current code name
subset_data <- df_move[df_move$Code == name, ]
# Check the number of relocations
num_relocations <- nrow(subset_data)
# Proceed if there are at least 5 relocations
if (num_relocations >= 5) {
# Convert subset_data to SpatialPointsDataFrame
subset_sp <- st_as_sf(subset_data, coords = c("x", "y"))
# Convert subset_sp to SpatialPoints object
subset_sp_points <- as(subset_sp, "Spatial")
# Calculate kernel UD
kde <- kernelUD(subset_sp_points, h = parh)
kde_list[[name]] <- kde
} else {
cat("Deleting KDE result for", name, "due to fewer than 5 relocations.\n")
# Delete this subset from the list
kde_list[[name]] <- NULL
}
}
library(homdista)
library(homdista)
library(homdista)
library(homdista)
library(homdista)
library(homdista)
roxygen2::roxygenize()
devtools::document()
library(homdista)
devtools::document()
roxygen2::roxygenize()
devtools::document()
library(homdista)
roxygen2::roxygenize()
devtools::document()
devtools::install_git("https://github.com/2023Jado/homdista")
library(homdista)
roxygen2::roxygenize()
library(homdista)
roxygen2::roxygenize()
devtools::document()
library(homdista)
roxygen2::roxygenize()
roxygen2::roxygenize()
devtools::document()
library(homdista)
roxygen2::roxygenize()
devtools::document()
roxygen2::roxygenize()
devtools::document()
library(homdista)
library(homdista)
library(homdista)
file <- read.csv("C:/Users/Jado/Documents/DFGF/RE_HR_analysis_2020-2022/Combined file RDB & KRC/test_test.csv")
data_df <- file
Id_name <- 'GORILLA_GROUP'
crs_epsg <- 32735
# Rename the column
names(data_df)[which(names(data_df) == Id_name)] <- "groupid"
tf <- "%m/%d/%y %I:%M %p"
# Change the time format
data_df$time <- as.POSIXct(data_df$timestamp, format = tf, tz="UTC")
# Remove the NA from data_df
data_df_no_na <- na.omit(data_df)
# Sort the dataset based on the timestamp column
no_na_df_sorted <- data_df_no_na[order(data_df_no_na$time), ]
# Identify duplicate timestamps
duplicate_indices <- duplicated(no_na_df_sorted$time) |
duplicated(no_na_df_sorted$time, fromLast = TRUE)
# Remove duplicate timestamps
no_na_data_unique <- no_na_df_sorted[!duplicate_indices, ]
# Create a "code name" column to be used for home range estimation
no_na_data_unique$Month_code <- month(no_na_data_unique$time)
library(lubridate)
# Create a "code name" column to be used for home range estimation
no_na_data_unique$Month_code <- month(no_na_data_unique$time)
no_na_data_unique$Year_code <- year(no_na_data_unique$time)
no_na_data_unique$Code <- paste(no_na_data_unique$Month_code, no_na_data_unique$Year_code, no_na_data_unique$groupid)
# Create move object with sorted dataset
df_move <- move(
x = no_na_data_unique$x,
y = no_na_data_unique$y,
time = as.POSIXct(no_na_data_unique$time, format = tf, tz = "UTC"),
data = no_na_data_unique,
Id = na_na_data_unique$groupid,
group = no_na_data_unique$Code,
crs = crs_epsg
)
library(move)
# Create move object with sorted dataset
df_move <- move(
x = no_na_data_unique$x,
y = no_na_data_unique$y,
time = as.POSIXct(no_na_data_unique$time, format = tf, tz = "UTC"),
data = no_na_data_unique,
Id = na_na_data_unique$groupid,
group = no_na_data_unique$Code,
crs = crs_epsg
)
# Change the projection
df_move <- spTransform(df_move,("+init=epsg:crs_epsg"))
# Change the projection
proj4string(df_move) <- CRS(paste0("+init=epsg:", crs_epsg))
df_move
library(homdista)
library(homdista)
file <- read.csv("C:/Users/Jado/Documents/DFGF/RE_HR_analysis_2020-2022/Combined file RDB & KRC/test_test.csv")
perc <- 90
perh <- 200
crs_epsg <- 32735
data_df <- file
# Rename the column
names(data_df)[which(names(data_df) == Id_name)] <- "groupid"
Id_name <-'GORILLA_GROUP'
# Rename the column
names(data_df)[which(names(data_df) == Id_name)] <- "groupid"
# Change the time format
data_df$time <- as.POSIXct(data_df$timestamp, format = tf, tz="UTC")
library(lubridate)
library(sp)
library(sf)
library(move)
# Change the time format
data_df$time <- as.POSIXct(data_df$timestamp, format = tf, tz="UTC")
tf <- "%m/%d/%y %I:%M %p"
# Change the time format
data_df$time <- as.POSIXct(data_df$timestamp, format = tf, tz="UTC")
# Remove the NA from data_df
data_df_no_na <- na.omit(data_df)
# Sort the dataset based on the timestamp column
no_na_df_sorted <- data_df_no_na[order(data_df_no_na$time), ]
# Identify duplicate timestamps
duplicate_indices <- duplicated(no_na_df_sorted$time) |
duplicated(no_na_df_sorted$time, fromLast = TRUE)
# Remove duplicate timestamps
no_na_data_unique <- no_na_df_sorted[!duplicate_indices, ]
# Create a "code name" column to be used for home range estimation
no_na_data_unique$Month_code <- month(no_na_data_unique$time)
no_na_data_unique$Year_code <- year(no_na_data_unique$time)
no_na_data_unique$Code <- paste(no_na_data_unique$Month_code, no_na_data_unique$Year_code, no_na_data_unique$groupid)
# Create move object with sorted dataset
df_move <- move(
x = no_na_data_unique$x,
y = no_na_data_unique$y,
time = as.POSIXct(no_na_data_unique$time, format = tf, tz = "UTC"),
data = no_na_data_unique,
Id = na_na_data_unique$groupid,
group = no_na_data_unique$Code,
crs = crs_epsg
)
df_move
# Change the projection
crscode <- crs_epsg
proj4string(df_move) <- CRS(paste0("+init=epsg:", crscode))
# Change the projection
crscode <- crs_epsg
crs(df_move) <- CRS(paste0("+init=epsg:", crscode))
df_move
library(homdista)
file <- read.csv("C:/Users/Jado/Documents/DFGF/RE_HR_analysis_2020-2022/Combined file RDB & KRC/test_test.csv")
Id_name <- 'GORILLA_GROUP'
crs_epsg <- 32735
tf <- "%m/%d/%y %I:%M %p"
data_df <- file
# Rename the column
names(data_df)[which(names(data_df) == Id_name)] <- "groupid"
# Change the time format
data_df$time <- as.POSIXct(data_df$timestamp, format = tf, tz="UTC")
# Remove the NA from data_df
data_df_no_na <- na.omit(data_df)
# Sort the dataset based on the timestamp column
no_na_df_sorted <- data_df_no_na[order(data_df_no_na$time), ]
# Identify duplicate timestamps
duplicate_indices <- duplicated(no_na_df_sorted$time) |
duplicated(no_na_df_sorted$time, fromLast = TRUE)
# Remove duplicate timestamps
no_na_data_unique <- no_na_df_sorted[!duplicate_indices, ]
# Create a "code name" column to be used for home range estimation
no_na_data_unique$Month_code <- month(no_na_data_unique$time)
library(lubridate)
library(mapview)
library(move)
data_df <- file
# Rename the column
names(data_df)[which(names(data_df) == Id_name)] <- "groupid"
# Change the time format
data_df$time <- as.POSIXct(data_df$timestamp, format = tf, tz="UTC")
# Remove the NA from data_df
data_df_no_na <- na.omit(data_df)
# Sort the dataset based on the timestamp column
no_na_df_sorted <- data_df_no_na[order(data_df_no_na$time), ]
# Identify duplicate timestamps
duplicate_indices <- duplicated(no_na_df_sorted$time) |
duplicated(no_na_df_sorted$time, fromLast = TRUE)
# Remove duplicate timestamps
no_na_data_unique <- no_na_df_sorted[!duplicate_indices, ]
# Create a "code name" column to be used for home range estimation
no_na_data_unique$Month_code <- month(no_na_data_unique$time)
no_na_data_unique$Year_code <- year(no_na_data_unique$time)
no_na_data_unique$Code <- paste(no_na_data_unique$Month_code, no_na_data_unique$Year_code, no_na_data_unique$groupid)
# Create move object with sorted dataset
df_move <- move(
x = no_na_data_unique$x,
y = no_na_data_unique$y,
time = as.POSIXct(no_na_data_unique$time, format = tf, tz = "UTC"),
data = no_na_data_unique,
Id = na_na_data_unique$groupid,
group = no_na_data_unique$Code,
crs = crs_epsg
)
# Change the projection
crscode <- crs_epsg
crs(df_move) <- CRS(paste0("+init=epsg:", crscode))
proj4string(df_move) <- CRS(paste0("+init=epsg:", crscode))
mapview(df_move)
mapview(df_move)
mapview(df_move)
# Change the projection
crscode <- crs_epsg
proj4string(df_move) <- CRS(paste0("+init=epsg:", crscode))
mapview(df_move)
data_df <- file
# Rename the column
names(data_df)[which(names(data_df) == Id_name)] <- "groupid"
# Change the time format
data_df$time <- as.POSIXct(data_df$timestamp, format = tf, tz="UTC")
# Remove the NA from data_df
data_df_no_na <- na.omit(data_df)
# Sort the dataset based on the timestamp column
no_na_df_sorted <- data_df_no_na[order(data_df_no_na$time), ]
# Identify duplicate timestamps
duplicate_indices <- duplicated(no_na_df_sorted$time) |
duplicated(no_na_df_sorted$time, fromLast = TRUE)
# Remove duplicate timestamps
no_na_data_unique <- no_na_df_sorted[!duplicate_indices, ]
# Create a "code name" column to be used for home range estimation
no_na_data_unique$Month_code <- month(no_na_data_unique$time)
no_na_data_unique$Year_code <- year(no_na_data_unique$time)
no_na_data_unique$Code <- paste(no_na_data_unique$Month_code, no_na_data_unique$Year_code, no_na_data_unique$groupid)
# Create move object with sorted dataset
df_move <- move(
x = no_na_data_unique$x,
y = no_na_data_unique$y,
time = as.POSIXct(no_na_data_unique$time, format = tf, tz = "UTC"),
data = no_na_data_unique,
Id = na_na_data_unique$groupid,
group = no_na_data_unique$Code,
crs = crs_epsg
)
# Change the projection
crscode <- crs_epsg
proj4string(df_move) <- CRS(paste0("+init=epsg:", crscode))
#'perc <- 95
#'
#' library(homdista)
#'
#' #Make the move object from data frame
#' moveObj <- homdista::moveObject(file, tf, Id_name, crs_epsg)
#'
#' #Create map with mapview
#' mapview(moveObj)
#'
moveObject <- function(file, tf, Id_name, crs_epsg){
# Read the csv data
data_df <- file
# Rename the column
names(data_df)[which(names(data_df) == Id_name)] <- "groupid"
# Change the time format
data_df$time <- as.POSIXct(data_df$timestamp, format = tf, tz="UTC")
# Remove the NA from data_df
data_df_no_na <- na.omit(data_df)
# Sort the dataset based on the timestamp column
no_na_df_sorted <- data_df_no_na[order(data_df_no_na$time), ]
# Identify duplicate timestamps
duplicate_indices <- duplicated(no_na_df_sorted$time) |
duplicated(no_na_df_sorted$time, fromLast = TRUE)
# Remove duplicate timestamps
no_na_data_unique <- no_na_df_sorted[!duplicate_indices, ]
# Create a "code name" column to be used for home range estimation
no_na_data_unique$Month_code <- month(no_na_data_unique$time)
no_na_data_unique$Year_code <- year(no_na_data_unique$time)
no_na_data_unique$Code <- paste(no_na_data_unique$Month_code, no_na_data_unique$Year_code, no_na_data_unique$groupid)
# Create move object with sorted dataset
df_move <- move(
x = no_na_data_unique$x,
y = no_na_data_unique$y,
time = as.POSIXct(no_na_data_unique$time, format = tf, tz = "UTC"),
data = no_na_data_unique,
Id = na_na_data_unique$groupid,
group = no_na_data_unique$Code,
crs = crs_epsg
)
# Change the projection
crscode <- crs_epsg
proj4string(df_move) <- CRS(paste0("+init=epsg:", crscode))
}
mapview(df_move)
df_move
mapview(df_move)
df_move
plot(df_move)
move::angle(df_move)
move::distance(df_move)
cc <- unlist(move::distance(df_move))
cc
library(homdista)
roxygenize2::roxygenize()
roxygen2::roxygenize()
devtools::document()
devtools::document()
rm(list = c("moveObject"))
roxygen2::roxygenize()
devtools::document()
library(homdista)
library(homdista)
library(homdista)
library(homdista)
library(homdista)
file <- read.csv("C:/Users/Jado/Documents/DFGF/RE_HR_analysis_2020-2022/Combined file RDB & KRC/test_test.csv")
library(lubridate)
library(sf)
library(sp)
library(move)
f <- homdista::moveObject(file, "%m/%d/%y %I:%M %p", "GORILLA_GROUP", 32735)
library(homdista)
file <- read.csv("C:/Users/Jado/Documents/DFGF/RE_HR_analysis_2020-2022/Combined file RDB & KRC/test_test.csv")
library(lubridate)
library(move)
f <- homdista::moveObject(file, "%m/%d/%y %I:%M %p", "GORILLA_GROUP", 32735)
plot(f)
move::disatance(df_move)
move::distance(df_move)
move::distance(f)
library(homdista)
move::angle(f)
usethat::vigette()
vignette(homdista)
library(homdista)
devtools::use_vignette("introduction")
usethat::use_vignette("introduction")
usethis::use_vignette("introduction")
library(homdista)
library(homdista)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(homdista)
# Read the file
file <- read.csv("C:/Users/Jado/Documents/EAGLE/Semester 2/Data/data.csv", header=T)
# Read the file
file <- read.csv("C:/Users/Jado/Documents/EAGLE/Semester2/Animal_movement/Data/data.csv", header=T)
# Estimating the home range size and walked distances per month
Homerange_distance <- homdista::homdista(file ,"%m/%d/%y %I:%M %p", 32735, "Animal", 90, 200)
library(homdista)
library(lubridate)
library(sf)
library(sp)
library(adehabitatLT)
library(adehabitatHR)
library(mapview)
library(ggplot2)
library(move)
# Estimating the home range size and walked distances per month
Homerange_distance <- homdista::homdista(file ,"%m/%d/%y %I:%M %p", 32735, "Animal", 90, 200)
Homerange_distance
# Determining and plotting the correlation between walked distance and utilized home range area
Correlation <- homdista::hodicor(Homerange_distance, "spearman")
plot(Correlation)
# Walked distance line paths
Distance <- homdista::distwalk(file, "%m/%d/%y %I:%M %p", 32735, "Animal")
mapview(Distance)
# Home range polygons
Homerange <- homdista::homekde(file, "%m/%d/%y %I:%M %p", 32735, "Animal", 90, 200)
st_as_sf(Homerange)
palette <- rainbow(length(unique(Homerange$Id)))
mapview(Homerange, zcol = "Id", col.regions = palette,
legend = TRUE, legend.title = "", legend.values = unique(Homerange$Id))
# Data frame to move object
Move <- homdista::moveObject(file, "%m/%d/%y %I:%M %p", "Animal", 32735)
plot(Move)
move::distance(Move)
move::angle(Move)
suppressWarnings({
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
})
library(homdista)
library(lubridate)
library(sf)
library(sp)
library(adehabitatLT)
library(adehabitatHR)
library(mapview)
library(ggplot2)
library(move)
# Read the file
file <- read.csv("C:/Users/Jado/Documents/EAGLE/Semester2/Animal_movement/Data/data.csv", header=T)
# Estimating the home range size and walked distances per month
Homerange_distance <- homdista::homdista(file ,"%m/%d/%y %I:%M %p", 32735, "Animal", 90, 200)
# Determining and plotting the correlation between walked distance and utilized home range area
Correlation <- homdista::hodicor(Homerange_distance, "spearman")
# Walked distance line paths
Distance <- homdista::distwalk(file, "%m/%d/%y %I:%M %p", 32735, "Animal")
mapview(Distance)
# Home range polygons
Homerange <- homdista::homekde(file, "%m/%d/%y %I:%M %p", 32735, "Animal", 90, 200)
st_as_sf(Homerange)
palette <- rainbow(length(unique(Homerange$Id)))
mapview(Homerange, zcol = "Id", col.regions = palette,
legend = TRUE, legend.title = "", legend.values = unique(Homerange$Id))
# Data frame to move object
Move <- homdista::moveObject(file, "%m/%d/%y %I:%M %p", "Animal", 32735)
plot(Move)
move::distance(Move)
move::angle(Move)
library(RStoolbox)
library(sf)
library(move)
library(lubridate)
library(amt)
library(ggplot2)
library(terra)
library(ctmm)
# Load traj data
load("C:/Users/Jado/Documents/EAGLE/Semester 2/Data/buffalo_utm.rda")
load("C:/Users/Jado/Documents/EAGLE/Semester2/Animal_movement/Data/buffalo_utm.rda")
load("C:/Users/Jado/Documents/EAGLE/Semester2/Animal_movement/Data/buffalo_env.rda")
raster::plot(buffalo_env)
raster::plot(raster(buffalo_env, 1))
points(buffalo_utm)
cilla <- buffalo_utm[["Cilla"]]
names(buffalo_env)
names(buffalo_utm)
indiv(buffalo_utm)
individual(buffalo_utm)
names(buffalo_utm$event.id)
buffalo_utm$event.id
(buffalo_utm
dev.off()
buffalo_utm
cilla <- cilla[timestamps(cilla) > min(timestamps(cilla)) + days(1), ]
cilla
cilla_telemetry <- as.telemetry(cilla)
cilla_telemetry
cilla_guess <- ctmm.guess(
cilla_telemetry, CTMM = ctmm(isotropic = T), interactive = F
)
cilla_select <- ctmm.select(
cilla_telemetry, cilla_guess
)
cilla_select$akde <- akde(cilla_telemetry, cilla_select)
plot(cilla_telemetry, UD=cilla_select$akde)
# Create predictor env dataset
predictors <- list(
"elev" = raster(buffalo_env, "elev"),
"slope"= raster(buffalo_env, "slope"),
"var_NDVI" = raster(buffalo_env, "var_NDVI")
)
cilla_rf_riemann <- rsf.fit(
cilla_telemetry, cilla_select$akde, R = predictors,
integrator = "Riemann"
)
summary(cilla_rf_riemann)
cilla_rsf_suitability <- suitability(
data = cilla_telemetry, CTMM = cilla_rf_riemann,
R = predictors, grid = crop(predictors[[1]], extent(cilla)*2)
)
raster::plot(cilla_rsf_suitability)
agde_cilla <- agde(cilla_telemetry, CTMM = cilla_rf_riemann,
R = predictors)
raster::plot(agde_cilla)
git commit --no-verify
git commit --no-verify
library(homdista)
usethis::use_readme_rmd
usethis::use_readme_rmd()
